{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os, json, pathlib, shutil, PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg_preprocess_input, decode_predictions as vgg_decode_predictions\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input as resnet_preprocess_input, decode_predictions as resnet_decode_predictions\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_preprocess_input, decode_predictions as inception_decode_predictions\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input as densenet_preprocess_input, decode_predictions as densenet_decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 18s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94674944/94668760 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102875136/102869336 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# preparing all the pre-trained models\n",
    "\n",
    "vgg_layer = VGG16(weights= 'imagenet', include_top= False, input_shape=(200, 200, 3))\n",
    "vgg_full_layer = VGG16(weights= 'imagenet', include_top= True, input_shape= None, classifier_activation='softmax')\n",
    "\n",
    "resnet_layer = ResNet50V2(weights= 'imagenet', include_top= False, input_shape=(200, 200, 3))\n",
    "resnet_full_layer = ResNet50V2(weights= 'imagenet', include_top= True, input_shape= None, classifier_activation='softmax')\n",
    "\n",
    "inception_layer = InceptionV3(weights= 'imagenet', include_top= False, input_shape=(200, 200, 3))\n",
    "inception_full_layer = InceptionV3(weights= 'imagenet', include_top= True, input_shape= None, classifier_activation='softmax')\n",
    "\n",
    "densenet_layer = DenseNet121(weights= 'imagenet', include_top= False, input_shape=(200, 200, 3))\n",
    "densenet_full_layer = DenseNet121(weights= 'imagenet', include_top= True, input_shape= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# getting into the files\n",
    "folder_dir = \"Places365_train\"\n",
    "val_file_dir = pathlib.Path(folder_dir)\n",
    "print(val_file_dir.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'random_discovery_cnt = len(list(pathlib.Path(val_file_dir, \\'random_discovery\\').glob(\"*.jpg\")))\\nprint(random_discovery_cnt)\\n\\ntotal_img_cnt = total_img_cnt - random_discovery_cnt\\nprint(total_img_cnt)'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_img_cnt = len(list(val_file_dir.glob(\"*/*.jpg\")))\n",
    "print(total_img_cnt)\n",
    "'''random_discovery_cnt = len(list(pathlib.Path(val_file_dir, 'random_discovery').glob(\"*.jpg\")))\n",
    "print(random_discovery_cnt)\n",
    "\n",
    "total_img_cnt = total_img_cnt - random_discovery_cnt\n",
    "print(total_img_cnt)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airfield', 'amusement-park', 'aquarium', 'bathroom', 'bus-station-indoor', 'canal-urban', 'church-outdoor', 'computer-room', 'crosswalk', 'gas-station', 'golf-course', 'gymnasium-indoor', 'restaurant-kitchen', 'tree-house', 'vineyard']\n"
     ]
    }
   ],
   "source": [
    "class_names = [name for name in os.listdir(folder_dir) if os.path.isdir(os.path.join(folder_dir, name))]\n",
    "#class_names.remove(\"random_discovery\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nums = []\n",
    "for class_name in class_names:\n",
    "  class_dir = pathlib.Path(folder_dir, class_name)\n",
    "  #each_class_imgs = list(class_dir.glob(\"*.jpg\"))\n",
    "  cl_length = len(list(class_dir.glob(\"*.jpg\")))\n",
    "  train_ratio = int(cl_length * 0.7)\n",
    "  test_ratio = int(cl_length * 0.2)\n",
    "  valid_ratio = cl_length - (train_ratio + test_ratio)\n",
    "\n",
    "  nums = np.zeros(cl_length)\n",
    "  nums[:test_ratio] = 1\n",
    "  nums[test_ratio : test_ratio + valid_ratio] = 2\n",
    "  np.random.shuffle(nums)\n",
    "  total_nums.append(list(nums))\n",
    "\n",
    "merged_nums = list(itertools.chain.from_iterable(total_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final layer of VGG16 : <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001BFE9772A48> and its shape : [None, 6, 6, 512]\n",
      "conv_base_shape :  [6, 6, 512]\n",
      "(1500, 6, 6, 512)\n",
      "18432\n"
     ]
    }
   ],
   "source": [
    "vgg_final_layer = list(vgg_layer.layers)[-1].output_shape\n",
    "vgg_final_layer = list(vgg_final_layer)\n",
    "print(\"final layer of VGG16 : \" +  str(list(vgg_layer.layers)[-1]) + \" and its shape : \" + str(vgg_final_layer))\n",
    "\n",
    "vgg_conv_layers = []\n",
    "for l in range(len(vgg_layer.layers)):\n",
    "  layer = vgg_layer.layers[l]\n",
    "  if 'Conv' not in layer.__class__.__name__:\n",
    "    continue\n",
    "  vgg_conv_layers.append((layer.name, layer.output.shape))\n",
    "\n",
    "vgg_conv_base_shape = []\n",
    "for i in vgg_final_layer:\n",
    "  if i != None:\n",
    "    vgg_conv_base_shape.append(i)\n",
    "print(\"conv_base_shape : \", vgg_conv_base_shape)\n",
    "\n",
    "vgg_feat_shape = tuple([total_img_cnt] + vgg_conv_base_shape)\n",
    "print(vgg_feat_shape)\n",
    "\n",
    "vgg_input_dimension = np.prod(vgg_conv_base_shape)\n",
    "print(vgg_input_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_base_shape :  [7, 7, 2048]\n",
      "(1500, 7, 7, 2048)\n",
      "100352\n"
     ]
    }
   ],
   "source": [
    "resnet_final_layer = list(resnet_layer.layers)[-1].output_shape\n",
    "resnet_final_layer = list(resnet_final_layer)\n",
    "\n",
    "resnet_conv_layers = []\n",
    "for l in range(len(resnet_layer.layers)):\n",
    "  layer = resnet_layer.layers[l]\n",
    "  if 'Conv' not in layer.__class__.__name__:\n",
    "    continue\n",
    "  resnet_conv_layers.append((layer.name, layer.output.shape))\n",
    "\n",
    "resnet_conv_base_shape = []\n",
    "for i in resnet_final_layer:\n",
    "  if i != None:\n",
    "    resnet_conv_base_shape.append(i)\n",
    "print(\"conv_base_shape : \", resnet_conv_base_shape)\n",
    "\n",
    "resnet_feat_shape = tuple([total_img_cnt] + resnet_conv_base_shape)\n",
    "print(resnet_feat_shape)\n",
    "\n",
    "resnet_input_dimension = np.prod(resnet_conv_base_shape)\n",
    "print(resnet_input_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_base_shape :  [4, 4, 2048]\n",
      "(1500, 4, 4, 2048)\n",
      "32768\n"
     ]
    }
   ],
   "source": [
    "inception_final_layer = list(inception_layer.layers)[-1].output_shape\n",
    "inception_final_layer = list(inception_final_layer)\n",
    "\n",
    "inception_conv_layers = []\n",
    "for l in range(len(inception_layer.layers)):\n",
    "  layer = inception_layer.layers[l]\n",
    "  if 'Conv' not in layer.__class__.__name__:\n",
    "    continue\n",
    "  inception_conv_layers.append((layer.name, layer.output.shape))\n",
    "\n",
    "inception_conv_base_shape = []\n",
    "for i in inception_final_layer:\n",
    "  if i != None:\n",
    "    inception_conv_base_shape.append(i)\n",
    "print(\"conv_base_shape : \", inception_conv_base_shape)\n",
    "\n",
    "inception_feat_shape = tuple([total_img_cnt] + inception_conv_base_shape)\n",
    "print(inception_feat_shape)\n",
    "\n",
    "inception_input_dimension = np.prod(inception_conv_base_shape)\n",
    "print(inception_input_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_base_shape :  [6, 6, 1024]\n",
      "(1500, 6, 6, 1024)\n",
      "36864\n"
     ]
    }
   ],
   "source": [
    "densenet_final_layer = list(densenet_layer.layers)[-1].output_shape\n",
    "densenet_final_layer = list(densenet_final_layer)\n",
    "\n",
    "densenet_conv_layers = []\n",
    "for l in range(len(densenet_layer.layers)):\n",
    "  layer = densenet_layer.layers[l]\n",
    "  if 'Conv' not in layer.__class__.__name__:\n",
    "    continue\n",
    "  densenet_conv_layers.append((layer.name, layer.output.shape))\n",
    "\n",
    "densenet_conv_base_shape = []\n",
    "for i in densenet_final_layer:\n",
    "  if i != None:\n",
    "    densenet_conv_base_shape.append(i)\n",
    "print(\"conv_base_shape : \", densenet_conv_base_shape)\n",
    "\n",
    "densenet_feat_shape = tuple([total_img_cnt] + densenet_conv_base_shape)\n",
    "print(densenet_feat_shape)\n",
    "\n",
    "densenet_input_dimension = np.prod(densenet_conv_base_shape)\n",
    "print(densenet_input_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('block5_conv3', TensorShape([None, 12, 12, 512]))\n",
      "('conv5_block3_3_conv', TensorShape([None, 7, 7, 2048]))\n",
      "('conv2d_93', TensorShape([None, 4, 4, 192]))\n",
      "('conv5_block16_2_conv', TensorShape([None, 6, 6, 32]))\n"
     ]
    }
   ],
   "source": [
    "print(vgg_conv_layers[-1])\n",
    "print(resnet_conv_layers[-1])\n",
    "print(inception_conv_layers[-1])\n",
    "print(densenet_conv_layers[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# leave out generator, and create all 4 models' feature at one function\n",
    "generator = datagen.flow_from_directory(val_file_dir, target_size=(200, 200), batch_size = batch_size, class_mode= 'categorical', shuffle=False)\n",
    "\n",
    "filepaths = []\n",
    "for filepath in generator.filepaths:\n",
    "  filepaths.append(filepath)\n",
    "  \n",
    "filenames = []\n",
    "for filename in generator.filenames:\n",
    "  filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_label = []\n",
    "file_names = []\n",
    "for file in filenames:\n",
    "  f = file.split(\"\\\\\")\n",
    "  ground_truth_label.append(f[0])\n",
    "  file_names.append(f[1])  \n",
    "\n",
    "index_list = list(range(0, total_img_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting with whole pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with whole pre-trained model \n",
    "\n",
    "def pretrained_prediction(img_paths, target_size, classifier, preprocess_input, decode_predictions):\n",
    "  whole_images = []\n",
    "  \n",
    "  for img_path in img_paths:\n",
    "    raw_img = image.load_img(img_path, target_size= target_size)\n",
    "    img = image.img_to_array(raw_img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    img = preprocess_input(img)\n",
    "    img = whole_images.append(img)\n",
    "\n",
    "  whole_images = np.vstack(whole_images)\n",
    "  prediction = classifier.predict(whole_images, batch_size = batch_size)\n",
    "  top_k = decode_predictions(prediction, top = 10)\n",
    "\n",
    "  return prediction, top_k, whole_images\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-7041c7c98a9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvgg_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg_topk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg_processed_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretrained_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg_full_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg_preprocess_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg_decode_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresnet_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnet_topk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnet_processed_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretrained_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnet_full_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnet_preprocess_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnet_decode_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-24020de17748>\u001b[0m in \u001b[0;36mpretrained_prediction\u001b[1;34m(img_paths, target_size, classifier, preprocess_input, decode_predictions)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhole_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m   \u001b[0mwhole_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhole_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m   \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhole_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[0mtop_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg_pred, vgg_topk, vgg_processed_imgs = pretrained_prediction(filepaths, (224, 224), vgg_full_layer, vgg_preprocess_input, vgg_decode_predictions)\n",
    "resnet_pred, resnet_topk, resnet_processed_imgs = pretrained_prediction(filepaths, (224, 224), resnet_full_layer, resnet_preprocess_input, resnet_decode_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_pred, inception_topk, inception_processed_imgs = pretrained_prediction(filepaths, (299, 299), inception_full_layer, inception_preprocess_input, inception_decode_predictions)\n",
    "densenet_pred, densenet_topk, densenet_processed_imgs = pretrained_prediction(filepaths, (224, 224), densenet_full_layer, densenet_preprocess_input, densenet_decode_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(generator, data_num, class_num, feature_shape, pretrained_model):\n",
    "  features = np.zeros(shape = feature_shape)\n",
    "  labels = np.zeros(shape=(data_num, class_num))\n",
    "  #generator = datagen.flow_from_directory(directory, target_size=(224, 224), batch_size = batch_size, class_mode= 'categorical', shuffle=False)\n",
    "  i = 0\n",
    "  for inputs_batch, labels_batch in generator:\n",
    "    features_batch = pretrained_model.predict(inputs_batch)\n",
    "    features[i * batch_size : (i+1) * batch_size] = features_batch\n",
    "    labels[i * batch_size : (i+1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * batch_size >= data_num:\n",
    "      break\n",
    "\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_features, vgg_labels = extract_features(generator, total_img_cnt, len(class_names), vgg_feat_shape, vgg_layer)\n",
    "resnet_features, resnet_labels = extract_features(generator, total_img_cnt, len(class_names), resnet_feat_shape, resnet_layer)\n",
    "inception_features, inception_labels = extract_features(generator, total_img_cnt, len(class_names), inception_feat_shape, inception_layer)\n",
    "densenet_features, densenet_labels = extract_features(generator, total_img_cnt, len(class_names), densenet_feat_shape, densenet_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels_int = []\n",
    "for idx in range(len(vgg_labels)):\n",
    "  total_labels_int.append(np.argmax(vgg_labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame({'index': index_list, 'label': ground_truth_label, 'label_int': total_labels_int, 'file_names' : file_names, 'file_path' : filepaths})\n",
    "pretrained_data_df = pd.DataFrame({'index': index_list, 'label': ground_truth_label, 'label_int': total_labels_int, 'file_names' : file_names, 'file_path' : filepaths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_data_df['vgg_pred_score'] = list(vgg_pred)\n",
    "pretrained_data_df['vgg_topk_pred'] = list(vgg_topk)\n",
    "pretrained_data_df['resnet_pred_score'] = list(resnet_pred)\n",
    "pretrained_data_df['resnet_topk_pred'] = list(resnet_topk)\n",
    "pretrained_data_df['inception_pred_score'] = list(inception_pred)\n",
    "pretrained_data_df['inception_topk_pred'] = list(inception_topk)\n",
    "pretrained_data_df['densenet_pred_score'] = list(densenet_pred)\n",
    "pretrained_data_df['densenet_topk_pred'] = list(densenet_topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pretrained_data_df.to_json(orient=\"records\")\n",
    "parsed = json.loads(result)\n",
    "with open(\"pretrained_places365_result.json\", \"w\") as outfile:\n",
    "  json.dump(parsed, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_features = np.reshape(vgg_features, (total_img_cnt, vgg_input_dimension))\n",
    "resnet_features = np.reshape(resnet_features, (total_img_cnt, resnet_input_dimension))\n",
    "inception_features = np.reshape(inception_features, (total_img_cnt, inception_input_dimension))\n",
    "densenet_features = np.reshape(densenet_features, (total_img_cnt, densenet_input_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3, random_state=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "CLUSTER_INT = 3\n",
    "\n",
    "vgg_clusters = KMeans(CLUSTER_INT, random_state = 0)\n",
    "vgg_clusters.fit(vgg_features)\n",
    "\n",
    "resnet_clusters = KMeans(CLUSTER_INT, random_state= 0)\n",
    "resnet_clusters.fit(resnet_features)\n",
    "\n",
    "inception_clusters = KMeans(CLUSTER_INT, random_state = 0)\n",
    "inception_clusters.fit(inception_features)\n",
    "\n",
    "densenet_clusters = KMeans(CLUSTER_INT, random_state= 0)\n",
    "densenet_clusters.fit(densenet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add classifier on pre-trained model\n",
    "vgg_model = keras.models.Sequential()\n",
    "#vgg_model.add(keras.layers.Reshape((vgg_input_dimension,), input_shape = tuple(vgg_conv_base_shape)))\n",
    "vgg_model.add(keras.layers.Dense(512, activation='relu', input_dim = vgg_input_dimension))\n",
    "vgg_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "vgg_model.add(keras.layers.Dense(len(class_names), activation = 'softmax'))\n",
    "vgg_model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "models.append(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = keras.models.Sequential()\n",
    "#resnet_model.add(keras.layers.Reshape((resnet_input_dimension,), input_shape = tuple(resnet_conv_base_shape)))\n",
    "resnet_model.add(keras.layers.Dense(512, activation='relu', input_dim = resnet_input_dimension))\n",
    "resnet_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "resnet_model.add(keras.layers.Dense(len(class_names), activation = 'softmax'))\n",
    "resnet_model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "models.append(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = keras.models.Sequential()\n",
    "#inception_model.add(keras.layers.Reshape((inception_input_dimension,), input_shape = tuple(inception_conv_base_shape)))\n",
    "inception_model.add(keras.layers.Dense(512, activation='relu', input_dim = inception_input_dimension))\n",
    "inception_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "inception_model.add(keras.layers.Dense(len(class_names), activation = 'softmax'))\n",
    "inception_model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "models.append(inception_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model = keras.models.Sequential()\n",
    "#densenet_model.add(keras.layers.Reshape((densenet_input_dimension,), input_shape = tuple(densenet_conv_base_shape)))\n",
    "densenet_model.add(keras.layers.Dense(512, activation='relu', input_dim = densenet_input_dimension))\n",
    "densenet_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "densenet_model.add(keras.layers.Dense(len(class_names), activation = 'softmax'))\n",
    "densenet_model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "models.append(densenet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nums = np.zeros(total_img_cnt)\n",
    "train_ratio = int(total_img_cnt * 0.6)\n",
    "test_ratio = int(total_img_cnt * 0.2)\n",
    "valid_ratio = total_img_cnt - (train_ratio + test_ratio)\n",
    "\n",
    "print(train_ratio)\n",
    "print(test_ratio)\n",
    "print(valid_ratio)\n",
    "\n",
    "nums[:test_ratio] = 1\n",
    "nums[test_ratio:test_ratio + valid_ratio] = 2\n",
    "np.random.shuffle(nums)'''\n",
    "\n",
    "pmt_order = np.random.permutation(np.arange(total_img_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put clustering result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_data_df = pd.DataFrame({'index': index_list, 'file_names': file_names, 'feature' : list(vgg_features), 'label' : list(vgg_labels), 'int_label' : total_labels_int, 'cluster': vgg_clusters.labels_, 'assign' : merged_nums})\n",
    "resnet_data_df = pd.DataFrame({'index': index_list, 'file_names': file_names, 'feature' : list(resnet_features), 'label' : list(resnet_labels), 'int_label' : total_labels_int, 'cluster': resnet_clusters.labels_, 'assign' : merged_nums})\n",
    "inception_data_df = pd.DataFrame({'index': index_list, 'file_names': file_names, 'feature' : list(inception_features), 'label' : list(inception_labels), 'int_label' : total_labels_int, 'cluster': inception_clusters.labels_, 'assign' : merged_nums})\n",
    "densenet_data_df = pd.DataFrame({'index': index_list, 'file_names': file_names, 'feature' : list(densenet_features), 'label' : list(densenet_labels), 'int_label' : total_labels_int,'cluster': densenet_clusters.labels_, 'assign' : merged_nums})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['assign'] = merged_nums\n",
    "data_df['vgg_clusters'] = vgg_clusters.labels_\n",
    "data_df['resnet_clusters'] = resnet_clusters.labels_\n",
    "data_df['inception_clusters'] = inception_clusters.labels_\n",
    "data_df['densenet_clusters'] = densenet_clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>label_int</th>\n",
       "      <th>file_names</th>\n",
       "      <th>file_path</th>\n",
       "      <th>assign</th>\n",
       "      <th>vgg_clusters</th>\n",
       "      <th>resnet_clusters</th>\n",
       "      <th>inception_clusters</th>\n",
       "      <th>densenet_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00000435.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000043...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00001163.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000116...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00001257.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000125...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00001316.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000131...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00001650.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000165...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     label  label_int                  file_names  \\\n",
       "0      0  airfield          0  Places365_val_00000435.jpg   \n",
       "1      1  airfield          0  Places365_val_00001163.jpg   \n",
       "2      2  airfield          0  Places365_val_00001257.jpg   \n",
       "3      3  airfield          0  Places365_val_00001316.jpg   \n",
       "4      4  airfield          0  Places365_val_00001650.jpg   \n",
       "\n",
       "                                           file_path  assign  vgg_clusters  \\\n",
       "0  Places365_train\\airfield\\Places365_val_0000043...     1.0             0   \n",
       "1  Places365_train\\airfield\\Places365_val_0000116...     0.0             1   \n",
       "2  Places365_train\\airfield\\Places365_val_0000125...     0.0             0   \n",
       "3  Places365_train\\airfield\\Places365_val_0000131...     1.0             0   \n",
       "4  Places365_train\\airfield\\Places365_val_0000165...     0.0             0   \n",
       "\n",
       "   resnet_clusters  inception_clusters  densenet_clusters  \n",
       "0                0                   2                  1  \n",
       "1                0                   2                  1  \n",
       "2                0                   2                  1  \n",
       "3                0                   0                  1  \n",
       "4                0                   2                  1  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_sf = data_df.iloc[pmt_order]\n",
    "vgg_data_df = vgg_data_df.iloc[pmt_order]\n",
    "resnet_data_df = resnet_data_df.iloc[pmt_order]\n",
    "inception_data_df = inception_data_df.iloc[pmt_order]\n",
    "densenet_data_df = densenet_data_df.iloc[pmt_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df_sf[data_df_sf['assign'] == 0]\n",
    "test_df = data_df_sf[data_df_sf['assign'] == 1]\n",
    "valid_df = data_df_sf[data_df_sf['assign'] == 2]\n",
    "\n",
    "vgg_train_df = vgg_data_df[vgg_data_df['assign'] == 0]\n",
    "vgg_test_df = vgg_data_df[vgg_data_df['assign'] == 1]\n",
    "vgg_valid_df = vgg_data_df[vgg_data_df['assign'] == 2]\n",
    "\n",
    "#vgg_train_df = vgg_train_df.sample(frac=1).reset_index(drop=True)\n",
    "#vgg_test_df = vgg_test_df.sample(frac=1).reset_index(drop=True)\n",
    "#vgg_valid_df = vgg_valid_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "resnet_train_df = resnet_data_df[resnet_data_df['assign'] == 0]\n",
    "resnet_test_df = resnet_data_df[resnet_data_df['assign'] == 1]\n",
    "resnet_valid_df = resnet_data_df[resnet_data_df['assign'] == 2]\n",
    "\n",
    "#resnet_train_df = resnet_train_df.sample(frac=1).reset_index(drop=True)\n",
    "#resnet_test_df = resnet_test_df.sample(frac=1).reset_index(drop=True)\n",
    "#resnet_valid_df = resnet_valid_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "inception_train_df = inception_data_df[inception_data_df['assign'] == 0]\n",
    "inception_test_df = inception_data_df[inception_data_df['assign'] == 1]\n",
    "inception_valid_df = inception_data_df[inception_data_df['assign'] == 2]\n",
    "\n",
    "#inception_train_df = inception_train_df.sample(frac=1).reset_index(drop=True)\n",
    "#inception_test_df = inception_test_df.sample(frac=1).reset_index(drop=True)\n",
    "#inception_valid_df = inception_valid_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "densenet_train_df = densenet_data_df[densenet_data_df['assign'] == 0]\n",
    "densenet_test_df = densenet_data_df[densenet_data_df['assign'] == 1]\n",
    "densenet_valid_df = densenet_data_df[densenet_data_df['assign'] == 2]\n",
    "\n",
    "#densenet_train_df = densenet_train_df.sample(frac=1).reset_index(drop=True)\n",
    "#densenet_test_df = densenet_test_df.sample(frac=1).reset_index(drop=True)\n",
    "#densenet_valid_df = densenet_valid_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_train_features = list(vgg_train_df['feature'])\n",
    "vgg_train_labels = list(vgg_train_df['label'])\n",
    "\n",
    "vgg_train_features = np.reshape(vgg_train_features, (len(vgg_train_df), vgg_input_dimension))\n",
    "vgg_train_labels = np.reshape(vgg_train_labels, (len(vgg_train_df), len(class_names)))\n",
    "\n",
    "vgg_test_features = list(vgg_test_df['feature'])\n",
    "vgg_test_labels = list(vgg_test_df['label'])\n",
    "\n",
    "vgg_test_features = np.reshape(vgg_test_features, (len(vgg_test_df), vgg_input_dimension))\n",
    "vgg_test_labels = np.reshape(vgg_test_labels, (len(vgg_test_df), len(class_names)))\n",
    "\n",
    "vgg_valid_features = list(vgg_valid_df['feature'])\n",
    "vgg_valid_labels = list(vgg_valid_df['label'])\n",
    "\n",
    "vgg_valid_features = np.reshape(vgg_valid_features, (len(vgg_valid_df), vgg_input_dimension))\n",
    "vgg_valid_labels = np.reshape(vgg_valid_labels, (len(vgg_valid_df), len(class_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_train_features = list(resnet_train_df['feature'])\n",
    "resnet_train_labels = list(resnet_train_df['label'])\n",
    "\n",
    "resnet_train_features = np.reshape(resnet_train_features, (len(resnet_train_df), resnet_input_dimension))\n",
    "resnet_train_labels = np.reshape(resnet_train_labels, (len(resnet_train_df), len(class_names)))\n",
    "\n",
    "resnet_test_features = list(resnet_test_df['feature'])\n",
    "resnet_test_labels = list(resnet_test_df['label'])\n",
    "\n",
    "resnet_test_features = np.reshape(resnet_test_features, (len(resnet_test_df), resnet_input_dimension))\n",
    "resnet_test_labels = np.reshape(resnet_test_labels, (len(resnet_test_df), len(class_names)))\n",
    "\n",
    "resnet_valid_features = list(resnet_valid_df['feature'])\n",
    "resnet_valid_labels = list(resnet_valid_df['label'])\n",
    "\n",
    "resnet_valid_features = np.reshape(resnet_valid_features, (len(resnet_valid_df), resnet_input_dimension))\n",
    "resnet_valid_labels = np.reshape(resnet_valid_labels, (len(resnet_valid_df), len(class_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_train_features = list(inception_train_df['feature'])\n",
    "inception_train_labels = list(inception_train_df['label'])\n",
    "\n",
    "inception_train_features = np.reshape(inception_train_features, (len(inception_train_df), inception_input_dimension))\n",
    "inception_train_labels = np.reshape(inception_train_labels, (len(inception_train_df), len(class_names)))\n",
    "\n",
    "inception_test_features = list(inception_test_df['feature'])\n",
    "inception_test_labels = list(inception_test_df['label'])\n",
    "\n",
    "inception_test_features = np.reshape(inception_test_features, (len(inception_test_df), inception_input_dimension))\n",
    "inception_test_labels = np.reshape(inception_test_labels, (len(inception_test_df), len(class_names)))\n",
    "\n",
    "inception_valid_features = list(inception_valid_df['feature'])\n",
    "inception_valid_labels = list(inception_valid_df['label'])\n",
    "\n",
    "inception_valid_features = np.reshape(inception_valid_features, (len(inception_valid_df), inception_input_dimension))\n",
    "inception_valid_labels = np.reshape(inception_valid_labels, (len(inception_valid_df), len(class_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_train_features = list(densenet_train_df['feature'])\n",
    "densenet_train_labels = list(densenet_train_df['label'])\n",
    "\n",
    "densenet_train_features = np.reshape(densenet_train_features, (len(densenet_train_df), densenet_input_dimension))\n",
    "densenet_train_labels = np.reshape(densenet_train_labels, (len(densenet_train_df), len(class_names)))\n",
    "\n",
    "densenet_test_features = list(densenet_test_df['feature'])\n",
    "densenet_test_labels = list(densenet_test_df['label'])\n",
    "\n",
    "densenet_test_features = np.reshape(densenet_test_features, (len(densenet_test_df), densenet_input_dimension))\n",
    "densenet_test_labels = np.reshape(densenet_test_labels, (len(densenet_test_df), len(class_names)))\n",
    "\n",
    "densenet_valid_features = list(densenet_valid_df['feature'])\n",
    "densenet_valid_labels = list(densenet_valid_df['label'])\n",
    "\n",
    "densenet_valid_features = np.reshape(densenet_valid_features, (len(densenet_valid_df), densenet_input_dimension))\n",
    "densenet_valid_labels = np.reshape(densenet_valid_labels, (len(densenet_valid_df), len(class_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 3s 91ms/step - loss: 3.4596 - accuracy: 0.1682 - val_loss: 1.6554 - val_accuracy: 0.4733\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 1.0534 - accuracy: 0.6664 - val_loss: 1.2038 - val_accuracy: 0.5933\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 0.5255 - accuracy: 0.8534 - val_loss: 1.1638 - val_accuracy: 0.6400\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 0.2377 - accuracy: 0.9470 - val_loss: 1.1080 - val_accuracy: 0.6800\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 0.0755 - accuracy: 0.9949 - val_loss: 1.0459 - val_accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 0.0437 - accuracy: 0.9966 - val_loss: 1.0194 - val_accuracy: 0.6933\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.0212 - accuracy: 0.9976 - val_loss: 1.0611 - val_accuracy: 0.6733\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.0276 - val_accuracy: 0.7067\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0444 - val_accuracy: 0.6867\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0702 - val_accuracy: 0.6933\n"
     ]
    }
   ],
   "source": [
    "vgg_train_history = vgg_model.fit(vgg_train_features, vgg_train_labels, epochs = 10, batch_size = batch_size, validation_data = (vgg_valid_features, vgg_valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 7s 302ms/step - loss: 12.1042 - accuracy: 0.3271 - val_loss: 3.0588 - val_accuracy: 0.6267\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 6s 282ms/step - loss: 0.5313 - accuracy: 0.9022 - val_loss: 2.4196 - val_accuracy: 0.6733\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 6s 274ms/step - loss: 0.1026 - accuracy: 0.9660 - val_loss: 2.3893 - val_accuracy: 0.7400\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 6s 273ms/step - loss: 0.0369 - accuracy: 0.9920 - val_loss: 2.5205 - val_accuracy: 0.7533\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 6s 276ms/step - loss: 0.0274 - accuracy: 0.9938 - val_loss: 2.0130 - val_accuracy: 0.7400\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 6s 272ms/step - loss: 0.0013 - accuracy: 0.9985 - val_loss: 2.0761 - val_accuracy: 0.7533\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 6s 272ms/step - loss: 1.4692e-04 - accuracy: 1.0000 - val_loss: 2.0968 - val_accuracy: 0.7600\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 6s 273ms/step - loss: 3.8316e-05 - accuracy: 1.0000 - val_loss: 2.0966 - val_accuracy: 0.7600\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 6s 272ms/step - loss: 2.2505e-05 - accuracy: 1.0000 - val_loss: 2.0962 - val_accuracy: 0.7600\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 6s 272ms/step - loss: 2.3089e-05 - accuracy: 1.0000 - val_loss: 2.0951 - val_accuracy: 0.7533\n"
     ]
    }
   ],
   "source": [
    "resnet_train_history = resnet_model.fit(resnet_train_features, resnet_train_labels, epochs = 10, batch_size = batch_size, validation_data = (resnet_valid_features, resnet_valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 4s 125ms/step - loss: 20.8936 - accuracy: 0.1788 - val_loss: 3.2893 - val_accuracy: 0.4933\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 1.8078 - accuracy: 0.6840 - val_loss: 1.3532 - val_accuracy: 0.7067\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 0.3926 - accuracy: 0.8937 - val_loss: 1.0649 - val_accuracy: 0.7200\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 0.0942 - accuracy: 0.9776 - val_loss: 0.9560 - val_accuracy: 0.7200\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 0.0303 - accuracy: 0.9934 - val_loss: 0.9791 - val_accuracy: 0.7400\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.8675 - val_accuracy: 0.7867\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.7800\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8845 - val_accuracy: 0.7733\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8729 - val_accuracy: 0.8000\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.7733\n"
     ]
    }
   ],
   "source": [
    "inception_train_history = inception_model.fit(inception_train_features, inception_train_labels, epochs = 10, batch_size = batch_size, validation_data = (inception_valid_features, inception_valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 4s 127ms/step - loss: 15.0296 - accuracy: 0.2234 - val_loss: 3.5094 - val_accuracy: 0.4933\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 1.3180 - accuracy: 0.7058 - val_loss: 1.1355 - val_accuracy: 0.7267\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 0.2032 - accuracy: 0.9419 - val_loss: 1.1364 - val_accuracy: 0.7267\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 0.0658 - accuracy: 0.9775 - val_loss: 0.8489 - val_accuracy: 0.7333\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 0.0233 - accuracy: 0.9947 - val_loss: 0.9829 - val_accuracy: 0.7333\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.8547 - val_accuracy: 0.7733\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8772 - val_accuracy: 0.7667\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8564 - val_accuracy: 0.7667\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 2s 112ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8554 - val_accuracy: 0.7667\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8735 - val_accuracy: 0.7733\n"
     ]
    }
   ],
   "source": [
    "densenet_train_history = densenet_model.fit(densenet_train_features, densenet_train_labels, epochs = 10, batch_size = batch_size, validation_data = (densenet_valid_features, densenet_valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 22ms/step - loss: 1.0613 - accuracy: 0.7033\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.5782 - accuracy: 0.8133\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9698 - accuracy: 0.7800\n",
      "10/10 [==============================] - 1s 28ms/step - loss: 0.7688 - accuracy: 0.8233\n"
     ]
    }
   ],
   "source": [
    "vgg_loss, vgg_acc = vgg_model.evaluate(vgg_test_features, vgg_test_labels)\n",
    "resnet_loss, resnet_acc = resnet_model.evaluate(resnet_test_features, resnet_test_labels)\n",
    "inception_loss, inception_acc = inception_model.evaluate(inception_test_features, inception_test_labels)\n",
    "densenet_loss, densenet_acc = densenet_model.evaluate(densenet_test_features, densenet_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_prediction_score = vgg_model.predict(vgg_features)\n",
    "resnet_prediction_score = resnet_model.predict(resnet_features)\n",
    "inception_prediction_score = inception_model.predict(inception_features)\n",
    "densenet_prediction_score = densenet_model.predict(densenet_features)\n",
    "\n",
    "vgg_test_prediction_score = vgg_model.predict(vgg_test_features)\n",
    "resnet_test_prediction_score = resnet_model.predict(resnet_test_features)\n",
    "inception_test_prediction_score = inception_model.predict(inception_test_features)\n",
    "densenet_test_prediction_score = densenet_model.predict(densenet_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_predicted_label = np.argmax(vgg_prediction_score, axis= -1)\n",
    "resnet_predicted_label = np.argmax(resnet_prediction_score, axis= -1)\n",
    "inception_predicted_label = np.argmax(inception_prediction_score, axis= -1)\n",
    "densenet_predicted_label = np.argmax(densenet_prediction_score, axis= -1)\n",
    "\n",
    "vgg_test_predicted_label = np.argmax(vgg_test_prediction_score, axis= -1)\n",
    "resnet_test_predicted_label = np.argmax(resnet_test_prediction_score, axis= -1)\n",
    "inception_test_predicted_label = np.argmax(inception_test_prediction_score, axis= -1)\n",
    "densenet_test_predicted_label = np.argmax(densenet_test_prediction_score, axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['vgg_predicted_score'] = list(vgg_prediction_score)\n",
    "data_df['vgg_predicted_label'] = list(vgg_predicted_label)\n",
    "data_df['resnet_predicted_score'] = list(resnet_prediction_score)\n",
    "data_df['resnet_predicted_label'] = list(resnet_predicted_label)\n",
    "data_df['inception_predicted_score'] = list(inception_prediction_score)\n",
    "data_df['inception_predicted_label'] = list(inception_predicted_label)\n",
    "data_df['densenet_predicted_score'] = list(densenet_prediction_score)\n",
    "data_df['densenet_predicted_label'] = list(densenet_predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dayeo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\dayeo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\dayeo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\dayeo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\dayeo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\dayeo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\dayeo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\dayeo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_df['vgg_predicted_score'] = list(vgg_test_prediction_score)\n",
    "test_df['vgg_predicted_label'] = list(vgg_test_predicted_label)\n",
    "test_df['resnet_predicted_score'] = list(resnet_test_prediction_score)\n",
    "test_df['resnet_predicted_label'] = list(resnet_test_predicted_label)\n",
    "test_df['inception_predicted_score'] = list(inception_test_prediction_score)\n",
    "test_df['inception_predicted_label'] = list(inception_test_predicted_label)\n",
    "test_df['densenet_predicted_score'] = list(densenet_test_prediction_score)\n",
    "test_df['densenet_predicted_label'] = list(densenet_test_predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>label_int</th>\n",
       "      <th>file_names</th>\n",
       "      <th>file_path</th>\n",
       "      <th>assign</th>\n",
       "      <th>vgg_clusters</th>\n",
       "      <th>resnet_clusters</th>\n",
       "      <th>inception_clusters</th>\n",
       "      <th>densenet_clusters</th>\n",
       "      <th>vgg_predicted_score</th>\n",
       "      <th>vgg_predicted_label</th>\n",
       "      <th>resnet_predicted_score</th>\n",
       "      <th>resnet_predicted_label</th>\n",
       "      <th>inception_predicted_score</th>\n",
       "      <th>inception_predicted_label</th>\n",
       "      <th>densenet_predicted_score</th>\n",
       "      <th>densenet_predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00000435.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000043...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.99974674, 2.024817e-07, 2.0296426e-07, 1.22...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 5.1224816e-25, 1.07096845e-19, 2.079632e...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 7.154506e-16, 7.5793236e-17, 7.346465e-1...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9999994, 9.487863e-10, 4.1840316e-12, 1.336...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00001163.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000116...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9992986, 8.948807e-07, 9.010984e-08, 6.5604...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.99999917, 8.4249674e-27, 3.1796505e-16, 1.3...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 2.5554897e-15, 2.025256e-15, 1.160988e-1...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.2707332e-10, 1.8986851e-10, 1.476803e-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00001257.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000125...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9999987, 2.3733987e-08, 2.0950275e-09, 1.19...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.1581774e-21, 1.379611e-20, 4.4922042e-...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.737587e-16, 9.750289e-17, 7.385888e-18...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9999999, 3.6842807e-11, 1.7205354e-10, 1.20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00001316.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000131...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.999113, 2.8065997e-05, 0.00021257324, 2.998...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 9.578816e-11, 1.1418956e-09, 7.918696e-2...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 2.3255526e-08, 4.8776386e-08, 3.4163753e...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.99998033, 2.7402982e-07, 9.795284e-07, 1.41...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00001650.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0000165...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.99860483, 5.6103386e-06, 9.597087e-07, 1.38...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 8.133172e-15, 6.897089e-14, 6.3469583e-3...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9965334, 0.003460946, 5.2859906e-07, 2.8672...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.99999726, 1.6226517e-07, 1.4607366e-09, 1.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     label  label_int                  file_names  \\\n",
       "0      0  airfield          0  Places365_val_00000435.jpg   \n",
       "1      1  airfield          0  Places365_val_00001163.jpg   \n",
       "2      2  airfield          0  Places365_val_00001257.jpg   \n",
       "3      3  airfield          0  Places365_val_00001316.jpg   \n",
       "4      4  airfield          0  Places365_val_00001650.jpg   \n",
       "\n",
       "                                           file_path  assign  vgg_clusters  \\\n",
       "0  Places365_train\\airfield\\Places365_val_0000043...     1.0             0   \n",
       "1  Places365_train\\airfield\\Places365_val_0000116...     0.0             1   \n",
       "2  Places365_train\\airfield\\Places365_val_0000125...     0.0             0   \n",
       "3  Places365_train\\airfield\\Places365_val_0000131...     1.0             0   \n",
       "4  Places365_train\\airfield\\Places365_val_0000165...     0.0             0   \n",
       "\n",
       "   resnet_clusters  inception_clusters  densenet_clusters  \\\n",
       "0                0                   2                  1   \n",
       "1                0                   2                  1   \n",
       "2                0                   2                  1   \n",
       "3                0                   0                  1   \n",
       "4                0                   2                  1   \n",
       "\n",
       "                                 vgg_predicted_score  vgg_predicted_label  \\\n",
       "0  [0.99974674, 2.024817e-07, 2.0296426e-07, 1.22...                    0   \n",
       "1  [0.9992986, 8.948807e-07, 9.010984e-08, 6.5604...                    0   \n",
       "2  [0.9999987, 2.3733987e-08, 2.0950275e-09, 1.19...                    0   \n",
       "3  [0.999113, 2.8065997e-05, 0.00021257324, 2.998...                    0   \n",
       "4  [0.99860483, 5.6103386e-06, 9.597087e-07, 1.38...                    0   \n",
       "\n",
       "                              resnet_predicted_score  resnet_predicted_label  \\\n",
       "0  [1.0, 5.1224816e-25, 1.07096845e-19, 2.079632e...                       0   \n",
       "1  [0.99999917, 8.4249674e-27, 3.1796505e-16, 1.3...                       0   \n",
       "2  [1.0, 1.1581774e-21, 1.379611e-20, 4.4922042e-...                       0   \n",
       "3  [1.0, 9.578816e-11, 1.1418956e-09, 7.918696e-2...                       0   \n",
       "4  [1.0, 8.133172e-15, 6.897089e-14, 6.3469583e-3...                       0   \n",
       "\n",
       "                           inception_predicted_score  \\\n",
       "0  [1.0, 7.154506e-16, 7.5793236e-17, 7.346465e-1...   \n",
       "1  [1.0, 2.5554897e-15, 2.025256e-15, 1.160988e-1...   \n",
       "2  [1.0, 1.737587e-16, 9.750289e-17, 7.385888e-18...   \n",
       "3  [1.0, 2.3255526e-08, 4.8776386e-08, 3.4163753e...   \n",
       "4  [0.9965334, 0.003460946, 5.2859906e-07, 2.8672...   \n",
       "\n",
       "   inception_predicted_label  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "                            densenet_predicted_score  densenet_predicted_label  \n",
       "0  [0.9999994, 9.487863e-10, 4.1840316e-12, 1.336...                         0  \n",
       "1  [1.0, 1.2707332e-10, 1.8986851e-10, 1.476803e-...                         0  \n",
       "2  [0.9999999, 3.6842807e-11, 1.7205354e-10, 1.20...                         0  \n",
       "3  [0.99998033, 2.7402982e-07, 9.795284e-07, 1.41...                         0  \n",
       "4  [0.99999726, 1.6226517e-07, 1.4607366e-09, 1.0...                         0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>label_int</th>\n",
       "      <th>file_names</th>\n",
       "      <th>file_path</th>\n",
       "      <th>assign</th>\n",
       "      <th>vgg_clusters</th>\n",
       "      <th>resnet_clusters</th>\n",
       "      <th>inception_clusters</th>\n",
       "      <th>densenet_clusters</th>\n",
       "      <th>vgg_predicted_score</th>\n",
       "      <th>vgg_predicted_label</th>\n",
       "      <th>resnet_predicted_score</th>\n",
       "      <th>resnet_predicted_label</th>\n",
       "      <th>inception_predicted_score</th>\n",
       "      <th>inception_predicted_label</th>\n",
       "      <th>densenet_predicted_score</th>\n",
       "      <th>densenet_predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>bus-station-indoor</td>\n",
       "      <td>4</td>\n",
       "      <td>Places365_val_00035800.jpg</td>\n",
       "      <td>Places365_train\\bus-station-indoor\\Places365_v...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[4.2226646e-05, 0.0056469585, 0.00025247058, 0...</td>\n",
       "      <td>5</td>\n",
       "      <td>[9.855952e-11, 2.3157393e-10, 9.423802e-09, 1....</td>\n",
       "      <td>4</td>\n",
       "      <td>[7.4550755e-08, 0.014703062, 0.0027483976, 0.0...</td>\n",
       "      <td>9</td>\n",
       "      <td>[5.928262e-07, 2.1464275e-05, 1.067274e-05, 1....</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>airfield</td>\n",
       "      <td>0</td>\n",
       "      <td>Places365_val_00027647.jpg</td>\n",
       "      <td>Places365_train\\airfield\\Places365_val_0002764...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.99936205, 1.1436932e-06, 1.3846201e-06, 7.9...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 5.9804993e-18, 1.3663284e-13, 5.103214e-...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 2.5019642e-15, 5.8192743e-18, 3.3786032e...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.753549e-11, 1.053702e-10, 2.6927574e-1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>aquarium</td>\n",
       "      <td>2</td>\n",
       "      <td>Places365_val_00031095.jpg</td>\n",
       "      <td>Places365_train\\aquarium\\Places365_val_0003109...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.00016762875, 0.00032846796, 0.9970776, 0.00...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.8263136e-13, 2.934561e-13, 0.99999976, 5.85...</td>\n",
       "      <td>2</td>\n",
       "      <td>[3.355493e-06, 0.0060943607, 0.94251704, 1.259...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0641062e-05, 0.0005633362, 0.99920315, 1.56...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>amusement-park</td>\n",
       "      <td>1</td>\n",
       "      <td>Places365_val_00000381.jpg</td>\n",
       "      <td>Places365_train\\amusement-park\\Places365_val_0...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0002024736, 0.9775283, 0.0009571813, 1.9317...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.9207837e-14, 1.0, 1.178999e-14, 2.2829999e-...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0718337e-06, 0.9991819, 1.2813993e-05, 2.27...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.8215196e-05, 0.9970108, 0.00014820223, 1.65...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>679</td>\n",
       "      <td>church-outdoor</td>\n",
       "      <td>6</td>\n",
       "      <td>Places365_val_00028877.jpg</td>\n",
       "      <td>Places365_train\\church-outdoor\\Places365_val_0...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[9.599688e-06, 0.0233073, 7.613521e-06, 3.1691...</td>\n",
       "      <td>6</td>\n",
       "      <td>[8.38315e-24, 5.8211065e-14, 4.427811e-19, 6.5...</td>\n",
       "      <td>6</td>\n",
       "      <td>[4.6280235e-10, 3.6205797e-08, 7.296379e-13, 1...</td>\n",
       "      <td>6</td>\n",
       "      <td>[2.431938e-08, 1.935451e-05, 3.2308034e-08, 2....</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index               label  label_int                  file_names  \\\n",
       "497    497  bus-station-indoor          4  Places365_val_00035800.jpg   \n",
       "71      71            airfield          0  Places365_val_00027647.jpg   \n",
       "287    287            aquarium          2  Places365_val_00031095.jpg   \n",
       "100    100      amusement-park          1  Places365_val_00000381.jpg   \n",
       "679    679      church-outdoor          6  Places365_val_00028877.jpg   \n",
       "\n",
       "                                             file_path  assign  vgg_clusters  \\\n",
       "497  Places365_train\\bus-station-indoor\\Places365_v...     1.0             2   \n",
       "71   Places365_train\\airfield\\Places365_val_0002764...     1.0             1   \n",
       "287  Places365_train\\aquarium\\Places365_val_0003109...     1.0             0   \n",
       "100  Places365_train\\amusement-park\\Places365_val_0...     1.0             0   \n",
       "679  Places365_train\\church-outdoor\\Places365_val_0...     1.0             1   \n",
       "\n",
       "     resnet_clusters  inception_clusters  densenet_clusters  \\\n",
       "497                1                   0                  2   \n",
       "71                 0                   2                  1   \n",
       "287                0                   2                  2   \n",
       "100                0                   0                  1   \n",
       "679                0                   2                  2   \n",
       "\n",
       "                                   vgg_predicted_score  vgg_predicted_label  \\\n",
       "497  [4.2226646e-05, 0.0056469585, 0.00025247058, 0...                    5   \n",
       "71   [0.99936205, 1.1436932e-06, 1.3846201e-06, 7.9...                    0   \n",
       "287  [0.00016762875, 0.00032846796, 0.9970776, 0.00...                    2   \n",
       "100  [0.0002024736, 0.9775283, 0.0009571813, 1.9317...                    1   \n",
       "679  [9.599688e-06, 0.0233073, 7.613521e-06, 3.1691...                    6   \n",
       "\n",
       "                                resnet_predicted_score  \\\n",
       "497  [9.855952e-11, 2.3157393e-10, 9.423802e-09, 1....   \n",
       "71   [1.0, 5.9804993e-18, 1.3663284e-13, 5.103214e-...   \n",
       "287  [1.8263136e-13, 2.934561e-13, 0.99999976, 5.85...   \n",
       "100  [1.9207837e-14, 1.0, 1.178999e-14, 2.2829999e-...   \n",
       "679  [8.38315e-24, 5.8211065e-14, 4.427811e-19, 6.5...   \n",
       "\n",
       "     resnet_predicted_label  \\\n",
       "497                       4   \n",
       "71                        0   \n",
       "287                       2   \n",
       "100                       1   \n",
       "679                       6   \n",
       "\n",
       "                             inception_predicted_score  \\\n",
       "497  [7.4550755e-08, 0.014703062, 0.0027483976, 0.0...   \n",
       "71   [1.0, 2.5019642e-15, 5.8192743e-18, 3.3786032e...   \n",
       "287  [3.355493e-06, 0.0060943607, 0.94251704, 1.259...   \n",
       "100  [4.0718337e-06, 0.9991819, 1.2813993e-05, 2.27...   \n",
       "679  [4.6280235e-10, 3.6205797e-08, 7.296379e-13, 1...   \n",
       "\n",
       "     inception_predicted_label  \\\n",
       "497                          9   \n",
       "71                           0   \n",
       "287                          2   \n",
       "100                          1   \n",
       "679                          6   \n",
       "\n",
       "                              densenet_predicted_score  \\\n",
       "497  [5.928262e-07, 2.1464275e-05, 1.067274e-05, 1....   \n",
       "71   [1.0, 1.753549e-11, 1.053702e-10, 2.6927574e-1...   \n",
       "287  [1.0641062e-05, 0.0005633362, 0.99920315, 1.56...   \n",
       "100  [2.8215196e-05, 0.9970108, 0.00014820223, 1.65...   \n",
       "679  [2.431938e-08, 1.935451e-05, 3.2308034e-08, 2....   \n",
       "\n",
       "     densenet_predicted_label  \n",
       "497                         9  \n",
       "71                          0  \n",
       "287                         2  \n",
       "100                         1  \n",
       "679                         6  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df['label_int'] == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_df.to_json(orient=\"records\")\n",
    "parsed = json.loads(result)\n",
    "with open(\"places_trained_data_result2.json\", \"w\") as outfile:\n",
    "  json.dump(parsed, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = test_df.to_json(orient=\"records\")\n",
    "parsed = json.loads(test_result)\n",
    "with open(\"places_trained_test_result2.json\", \"w\") as outfile:\n",
    "  json.dump(parsed, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saliency Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_map(model, imgs, last_conv_name):\n",
    "  with tf.GradientTape() as tape:\n",
    "    last_conv_layer = model.get_layer(last_conv_name)\n",
    "    print(last_conv_layer)\n",
    "    iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n",
    "    print(model.inputs)\n",
    "    print(model.output)\n",
    "    print(last_conv_layer.output)\n",
    "    model_out, last_conv_layer = iterate(imgs)\n",
    "    class_out = model_out[:, np.argmax(model_out[0])]\n",
    "    grads = tape.gradient(class_out, last_conv_layer)\n",
    "    pooled_grads = tf.keras.backend.mean(grads, axis = (0,1,2))\n",
    "\n",
    "  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis = -1)\n",
    "\n",
    "  heatmap = np.maximum(heatmap, 0)\n",
    "  heatmap /= np.max(heatmap)\n",
    "  heatmap = heatmap.reshape((7,7))\n",
    "\n",
    "  return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_full_model = vgg_layer\n",
    "flatten = keras.layers.Flatten()(vgg_full_model.layers[-1].output)\n",
    "dense1 = keras.layers.Dense(512, activation='relu')(flatten)\n",
    "dense2 = keras.layers.Dense(512, activation = 'relu')(dense1)\n",
    "output = keras.layers.Dense(20, activation = 'softmax')(dense2)\n",
    "vgg_full_model = keras.models.Model(inputs = vgg_full_model.inputs, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_full_model = resnet_layer\n",
    "flatten = keras.layers.Flatten()(resnet_full_model.layers[-1].output)\n",
    "dense1 = keras.layers.Dense(512, activation='relu')(flatten)\n",
    "dense2 = keras.layers.Dense(512, activation = 'relu')(dense1)\n",
    "output = keras.layers.Dense(20, activation = 'softmax')(dense2)\n",
    "resnet_full_model = keras.models.Model(inputs = resnet_full_model.inputs, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_full_model = inception_layer\n",
    "flatten = keras.layers.Flatten()(inception_full_model.layers[-1].output)\n",
    "dense1 = keras.layers.Dense(512, activation='relu')(flatten)\n",
    "dense2 = keras.layers.Dense(512, activation = 'relu')(dense1)\n",
    "output = keras.layers.Dense(20, activation = 'softmax')(dense2)\n",
    "inception_full_model = keras.models.Model(inputs = inception_full_model.inputs, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_full_model.compile(optimizer=tf.keras.optimizers.Adam(), loss = tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.losses.CategoricalCrossentropy at 0x1c02808a408>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_full_model.compiled_loss._losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_full_model.save(\"inception_full_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_full_model = densenet_layer\n",
    "flatten = keras.layers.Flatten()(densenet_full_model.layers[-1].output)\n",
    "dense1 = keras.layers.Dense(512, activation='relu')(flatten)\n",
    "dense2 = keras.layers.Dense(512, activation = 'relu')(dense1)\n",
    "output = keras.layers.Dense(20, activation = 'softmax')(dense2)\n",
    "densenet_full_model = keras.models.Model(inputs = densenet_full_model.inputs, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inception_processed_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-4f4175641b82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minception_processed_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'inception_processed_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "inception_processed_imgs[id].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_5')>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_layer.layers[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out, last_conv_layer = iterate(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f32045bbd30>\n",
      "[<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_5')>]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), name='dense_23/Softmax:0', description=\"created by layer 'dense_23'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 5, 5, 1536), dtype=tf.float32, name=None), name='conv_7b/Conv2D:0', description=\"created by layer 'conv_7b'\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer model_6: expected shape=(None, 224, 224, 3), found shape=(1, 299, 299, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-633f77ebdd0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcur_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception_processed_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception_full_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minception_conv_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-198ce7ef2482>\u001b[0m in \u001b[0;36msaliency_map\u001b[0;34m(model, imgs, last_conv_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_conv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mclass_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/stak/users/ohda/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/stak/users/ohda/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    272\u001b[0m                              \u001b[0;34m' is incompatible with layer '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                              \u001b[0;34m': expected shape='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                              ', found shape=' + display_shape(x.shape))\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer model_6: expected shape=(None, 224, 224, 3), found shape=(1, 299, 299, 3)"
     ]
    }
   ],
   "source": [
    "id = 155\n",
    "\n",
    "cur_img = np.expand_dims(inception_processed_imgs[id], axis = 0)\n",
    "hmap = saliency_map(inception_full_model, cur_img, inception_conv_layers[-1][0])\n",
    "plt.matshow(hmap)\n",
    "\n",
    "img = cv2.imread(filepath[id])\n",
    "\n",
    "INTENSITY = 0.5\n",
    "\n",
    "heatmap = cv2.resize(hmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "salient_img = heatmap * INTENSITY + img\n",
    "cv2.imwrite('dataset/salient_img.jpg', salient_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk = np.expand_dims(resnet_processed_imgs[234], axis = 0)\n",
    "kkk.shape\n",
    "\n",
    "h = saliency_map(resnet_full_model, kkk, resnet_conv_layers[-1][0])\n",
    "\n",
    "plt.matshow(h)\n",
    "plt.show()\n",
    "\n",
    "iii = cv2.imread(filepaths[234])\n",
    "\n",
    "INTENSITY = 0.5\n",
    "heatmap = cv2.resize(h, (iii.shape[1], iii.shape[0]))\n",
    "heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "iii = heatmap * INTENSITY + iii\n",
    "\n",
    "cv2.imwrite('dataset/cam1.jpg', iii)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
