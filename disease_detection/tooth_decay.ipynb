{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os, json, pathlib, shutil, PIL\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/snginh/toothdecay/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_layer = DenseNet121(weights= 'imagenet', include_top= False, input_shape=(224, 224, 3))\n",
    "inception_layer = InceptionV3(weights= 'imagenet', include_top= False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "test_folder_dir = \"tooth_decay/teeth_dataset/test/\"\n",
    "train_folder_dir = \"tooth_decay/teeth_dataset/train/\"\n",
    "test_file_dir = pathlib.Path(test_folder_dir)\n",
    "train_file_dir = pathlib.Path(train_folder_dir)\n",
    "print(train_file_dir.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"tooth_decay/teeth_dataset/test.csv\")\n",
    "train_dataset = pd.read_csv(\"tooth_decay/teeth_dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "test_img_cnt = len(test_dataset['images'])\n",
    "#train_img_cnt = len(train_dataset['images'])\n",
    "train_img_cnt = 35\n",
    "print(test_img_cnt)\n",
    "print(train_img_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caries', 'no-caries']\n"
     ]
    }
   ],
   "source": [
    "class_names = [name for name in os.listdir(test_folder_dir) if os.path.isdir(os.path.join(test_folder_dir, name))]\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(directory, data_num, class_num, feature_shape, pretrained_model):\n",
    "  features = np.zeros(shape = feature_shape)\n",
    "  labels = np.zeros(shape=(data_num, class_num))\n",
    "  generator = datagen.flow_from_directory(directory, target_size=(224, 224), batch_size = batch_size, class_mode= 'categorical', shuffle=False)\n",
    "  i = 0\n",
    "  for inputs_batch, labels_batch in generator:\n",
    "    features_batch = pretrained_model.predict(inputs_batch)\n",
    "    features[i * batch_size : (i+1) * batch_size] = features_batch\n",
    "    labels[i * batch_size : (i+1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * batch_size >= data_num:\n",
    "      break\n",
    "\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final layer of VGG16 : <keras.layers.merge.Concatenate object at 0x0000021F65709BC8> and its shape : [None, 5, 5, 2048]\n",
      "conv_base_shape :  [5, 5, 2048]\n",
      "(35, 5, 5, 2048)\n",
      "(14, 5, 5, 2048)\n",
      "51200\n"
     ]
    }
   ],
   "source": [
    "inception_final_layer = list(inception_layer.layers)[-1].output_shape\n",
    "inception_final_layer = list(inception_final_layer)\n",
    "print(\"final layer of VGG16 : \" +  str(list(inception_layer.layers)[-1]) + \" and its shape : \" + str(inception_final_layer))\n",
    "\n",
    "inc_conv_layers = []\n",
    "for l in range(len(inception_layer.layers)):\n",
    "  layer = inception_layer.layers[l]\n",
    "  if 'Conv' not in layer.__class__.__name__:\n",
    "    continue\n",
    "  inc_conv_layers.append((layer.name, layer.output.shape))\n",
    "\n",
    "inc_conv_base_shape = []\n",
    "for i in inception_final_layer:\n",
    "  if i != None:\n",
    "    inc_conv_base_shape.append(i)\n",
    "print(\"conv_base_shape : \", inc_conv_base_shape)\n",
    "\n",
    "train_inc_feat_shape = tuple([train_img_cnt] + inc_conv_base_shape)\n",
    "print(train_inc_feat_shape)\n",
    "\n",
    "test_inc_feat_shape = tuple([test_img_cnt] + inc_conv_base_shape)\n",
    "print(test_inc_feat_shape)\n",
    "\n",
    "inc_input_dimension = np.prod(inc_conv_base_shape)\n",
    "print(inc_input_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_inc_features, train_inc_labels = extract_features(train_file_dir, train_img_cnt, len(class_names), train_inc_feat_shape, inception_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_inc_features, test_inc_labels = extract_features(test_file_dir, test_img_cnt, len(class_names), test_inc_feat_shape, inception_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inc_features = np.reshape(train_inc_features, (train_img_cnt, inc_input_dimension))\n",
    "test_inc_features = np.reshape(test_inc_features, (test_img_cnt, inc_input_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add classifier on pre-trained model\n",
    "inception_model = keras.models.Sequential()\n",
    "inception_model.add(keras.layers.Dense(128, activation='relu', input_dim = inc_input_dimension))\n",
    "inception_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "inception_model.add(keras.layers.Dense(len(class_names), activation = 'softmax'))\n",
    "inception_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmt_order = np.random.permutation(np.arange(train_img_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 1s 32ms/step - loss: 2.5581 - accuracy: 0.5429\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0516 - accuracy: 0.9714\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4335 - accuracy: 0.9714\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1454 - accuracy: 0.9714\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0046 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "inc_train_history = inception_model.fit(train_inc_features, train_inc_labels, epochs = 5, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 158ms/step - loss: 0.3274 - accuracy: 0.9286\n"
     ]
    }
   ],
   "source": [
    "inc_loss, inc_acc = inception_model.evaluate(test_inc_features, test_inc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_test_prediction_score = inception_model.predict(test_inc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_test_predicted_label = np.argmax(inc_test_prediction_score, axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ab9860aa67bcbf622fdb102e63207459bbb25b20412deafaf9e196d9ec0185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
